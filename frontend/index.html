<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Emotion-Aware AI Voice Engine</title>
  <style>
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    :root {
      --bg:      #0f0f13;
      --surface: #1c1c24;
      --accent:  #7c5cfc;
      --accent2: #fc5c7c;
      --text:    #e8e8f0;
      --muted:   #6b6b80;
      --border:  #2e2e3e;
      --radius:  12px;
    }

    body {
      background: var(--bg);
      color: var(--text);
      font-family: 'Segoe UI', system-ui, sans-serif;
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 32px 16px;
      gap: 24px;
    }

    h1 {
      font-size: 1.6rem;
      font-weight: 700;
      background: linear-gradient(135deg, var(--accent), var(--accent2));
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      text-align: center;
    }

    .subtitle { color: var(--muted); font-size: 0.85rem; text-align: center; }

    .card {
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 20px;
      width: 100%;
      max-width: 660px;
    }

    .card h2 { font-size: 0.9rem; text-transform: uppercase;
                letter-spacing: .06em; color: var(--muted); margin-bottom: 14px; }

    /* Controls */
    .controls { display: flex; gap: 10px; flex-wrap: wrap; }

    button {
      padding: 10px 20px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      font-weight: 600;
      font-size: 0.9rem;
      transition: opacity .15s, transform .1s;
    }
    button:active { transform: scale(.97); }
    button:disabled { opacity: .4; cursor: not-allowed; }

    #btn-record  { background: var(--accent);  color: #fff; }
    #btn-stop    { background: var(--accent2); color: #fff; }
    #btn-upload  { background: #2e2e3e;        color: var(--text); }

    #file-input  { display: none; }

    /* Status */
    #status {
      font-size: 0.82rem;
      padding: 6px 12px;
      border-radius: 6px;
      background: #1a1a26;
      color: var(--muted);
      display: inline-block;
      margin-top: 10px;
    }
    #status.active { color: #6dffb3; }
    #status.error  { color: #ff6d6d; }

    /* VAD indicator */
    .vad-bar {
      height: 6px;
      border-radius: 3px;
      background: var(--border);
      margin-top: 12px;
      overflow: hidden;
    }
    .vad-fill {
      height: 100%;
      width: 0%;
      background: linear-gradient(90deg, var(--accent), var(--accent2));
      transition: width .1s;
    }

    /* Transcript */
    #transcript {
      min-height: 60px;
      background: #13131c;
      border-radius: 8px;
      padding: 12px;
      font-size: 0.95rem;
      line-height: 1.6;
      color: var(--text);
      white-space: pre-wrap;
    }

    /* Emotion */
    .emotion-display {
      display: flex;
      align-items: center;
      gap: 14px;
      flex-wrap: wrap;
    }

    .emotion-badge {
      padding: 8px 18px;
      border-radius: 20px;
      font-weight: 700;
      font-size: 1rem;
      text-transform: capitalize;
      background: var(--border);
      color: var(--text);
      transition: background .3s;
    }

    .intensity-bar {
      flex: 1;
      min-width: 120px;
      height: 10px;
      background: var(--border);
      border-radius: 5px;
      overflow: hidden;
    }
    .intensity-fill {
      height: 100%;
      width: 0%;
      border-radius: 5px;
      background: linear-gradient(90deg, var(--accent), var(--accent2));
      transition: width .4s ease;
    }

    /* Probs chart */
    .probs { display: flex; flex-direction: column; gap: 6px; margin-top: 12px; }
    .prob-row { display: flex; align-items: center; gap: 8px; }
    .prob-label { width: 64px; font-size: 0.78rem; color: var(--muted); text-align: right; }
    .prob-bar {
      flex: 1; height: 8px; background: var(--border);
      border-radius: 4px; overflow: hidden;
    }
    .prob-fill { height: 100%; background: var(--accent); border-radius: 4px;
                 transition: width .4s ease; }
    .prob-val { width: 38px; font-size: 0.75rem; color: var(--muted); }

    /* Features */
    .features {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(140px, 1fr));
      gap: 8px;
      margin-top: 8px;
    }
    .feat {
      background: #13131c;
      border-radius: 8px;
      padding: 8px 10px;
      font-size: 0.78rem;
    }
    .feat-key  { color: var(--muted); }
    .feat-val  { font-weight: 700; color: var(--text); }

    /* Metrics */
    .metrics {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 4px;
    }
    .metric {
      background: #13131c;
      border-radius: 8px;
      padding: 8px 14px;
      font-size: 0.82rem;
      text-align: center;
    }
    .metric-label { color: var(--muted); font-size: 0.7rem; text-transform: uppercase; }
    .metric-val   { font-weight: 700; font-size: 1rem; }

    /* Audio player */
    audio { width: 100%; border-radius: 8px; margin-top: 4px; }

    /* Emotion badge colors */
    .em-neutral  { background: #2e2e4e; color: #a0a0d0; }
    .em-happy    { background: #3a2e0a; color: #ffd95c; }
    .em-sad      { background: #0a1a3a; color: #5c9ffd; }
    .em-angry    { background: #3a0a0a; color: #fd5c5c; }
    .em-excited  { background: #1a0a3a; color: #c05cfd; }
    .em-calm     { background: #0a2e1a; color: #5cfd9f; }
  </style>
</head>
<body>
  <h1>Emotion-Aware AI Voice Engine</h1>
  <p class="subtitle">VAD → Whisper STT → Prosody + Sentiment Fusion → Emotion TTS</p>

  <!-- ── Input ─────────────────────────────────────────────────────────── -->
  <div class="card">
    <h2>Input</h2>
    <div class="controls">
      <button id="btn-record">● Record</button>
      <button id="btn-stop" disabled>■ Stop</button>
      <button id="btn-upload">↑ Upload File</button>
      <input type="file" id="file-input" accept="audio/*" />
    </div>
    <div id="status">Idle</div>
    <div class="vad-bar"><div class="vad-fill" id="vad-fill"></div></div>
  </div>

  <!-- ── Transcript ─────────────────────────────────────────────────────── -->
  <div class="card">
    <h2>Transcript</h2>
    <div id="transcript">—</div>
  </div>

  <!-- ── Emotion ───────────────────────────────────────────────────────── -->
  <div class="card">
    <h2>Emotion Analysis</h2>
    <div class="emotion-display">
      <div class="emotion-badge" id="emotion-badge">—</div>
      <div style="flex:1">
        <div style="font-size:.75rem;color:var(--muted);margin-bottom:4px">Intensity</div>
        <div class="intensity-bar"><div class="intensity-fill" id="intensity-fill"></div></div>
      </div>
      <div style="font-weight:700;font-size:1.2rem" id="intensity-val">—</div>
    </div>

    <!-- Probability bars -->
    <div class="probs" id="probs-container"></div>

    <!-- Audio features -->
    <div style="margin-top:14px;font-size:.8rem;color:var(--muted);">Prosody Features</div>
    <div class="features" id="features-container"></div>
  </div>

  <!-- ── Output Audio ───────────────────────────────────────────────────── -->
  <div class="card">
    <h2>Response Audio</h2>
    <audio id="audio-player" controls></audio>
  </div>

  <!-- ── Latency Metrics ───────────────────────────────────────────────── -->
  <div class="card">
    <h2>Pipeline Latency</h2>
    <div class="metrics" id="metrics-container">
      <div class="metric"><div class="metric-label">VAD</div><div class="metric-val" id="m-vad">—</div></div>
      <div class="metric"><div class="metric-label">STT</div><div class="metric-val" id="m-stt">—</div></div>
      <div class="metric"><div class="metric-label">Emotion</div><div class="metric-val" id="m-emotion">—</div></div>
      <div class="metric"><div class="metric-label">TTS</div><div class="metric-val" id="m-tts">—</div></div>
      <div class="metric"><div class="metric-label">Total</div><div class="metric-val" id="m-total">—</div></div>
    </div>
  </div>

<script>
// ── Config ──────────────────────────────────────────────────────────────────
const WS_URL = `ws://${location.host}/ws/voice`;
const API    = `http://${location.host}`;
const LABELS = ["neutral","happy","sad","angry","excited","calm"];

// ── State ────────────────────────────────────────────────────────────────────
let ws, mediaRecorder, audioChunks = [];
let receivedWavChunks = [];

// ── DOM refs ─────────────────────────────────────────────────────────────────
const btnRecord    = document.getElementById("btn-record");
const btnStop      = document.getElementById("btn-stop");
const btnUpload    = document.getElementById("btn-upload");
const fileInput    = document.getElementById("file-input");
const statusEl     = document.getElementById("status");
const transcriptEl = document.getElementById("transcript");
const emBadge      = document.getElementById("emotion-badge");
const intFill      = document.getElementById("intensity-fill");
const intVal       = document.getElementById("intensity-val");
const probsCont    = document.getElementById("probs-container");
const featsCont    = document.getElementById("features-container");
const audioPlayer  = document.getElementById("audio-player");
const vadFill      = document.getElementById("vad-fill");

// ── Init probability bars ────────────────────────────────────────────────────
probsCont.innerHTML = LABELS.map(l => `
  <div class="prob-row">
    <div class="prob-label">${l}</div>
    <div class="prob-bar"><div class="prob-fill" id="prob-${l}" style="width:0%"></div></div>
    <div class="prob-val" id="probv-${l}">0%</div>
  </div>`).join("");

// ── Status helper ────────────────────────────────────────────────────────────
function setStatus(msg, cls="") {
  statusEl.textContent = msg;
  statusEl.className = cls;
}

// ── WebSocket pipeline ───────────────────────────────────────────────────────
function openWS() {
  ws = new WebSocket(WS_URL);

  ws.onopen = () => {
    ws.send(JSON.stringify({ type: "config", language: "ko", speaker: null }));
    setStatus("Connected · Recording…", "active");
  };

  ws.onmessage = ({ data }) => {
    const msg = JSON.parse(data);

    if (msg.type === "vad_event") {
      vadFill.style.width = (msg.confidence * 100) + "%";
    }

    if (msg.type === "final_transcript") {
      transcriptEl.textContent = msg.text || "(no speech detected)";
    }

    if (msg.type === "emotion") {
      updateEmotion(msg);
    }

    if (msg.type === "audio_chunk") {
      receivedWavChunks.push(base64ToUint8(msg.data));
      if (msg.is_last) {
        const blob = new Blob(receivedWavChunks, { type: "audio/wav" });
        audioPlayer.src = URL.createObjectURL(blob);
        audioPlayer.play();
        receivedWavChunks = [];
      }
    }

    if (msg.type === "metrics") {
      document.getElementById("m-vad").textContent    = msg.vad_ms    + " ms";
      document.getElementById("m-stt").textContent    = msg.stt_ms    + " ms";
      document.getElementById("m-emotion").textContent= msg.emotion_ms+ " ms";
      document.getElementById("m-tts").textContent    = msg.tts_ms    + " ms";
      document.getElementById("m-total").textContent  = msg.total_ms  + " ms";
      setStatus(`Done · total ${msg.total_ms} ms`, "active");
    }

    if (msg.type === "error") {
      setStatus("Error: " + msg.message, "error");
    }
  };

  ws.onerror = () => setStatus("WebSocket error", "error");
  ws.onclose = () => { vadFill.style.width = "0%"; };
}

// ── Emotion display ──────────────────────────────────────────────────────────
function updateEmotion(msg) {
  const { emotion_label, intensity, probabilities, features_summary } = msg;

  // Badge
  LABELS.forEach(l => emBadge.classList.remove("em-" + l));
  emBadge.textContent = emotion_label;
  emBadge.classList.add("em-" + emotion_label);

  // Intensity
  const pct = Math.round(intensity * 100);
  intFill.style.width = pct + "%";
  intVal.textContent  = pct + "%";

  // Probability bars
  for (const [lbl, prob] of Object.entries(probabilities)) {
    const w = Math.round(prob * 100);
    const fill = document.getElementById("prob-" + lbl);
    const val  = document.getElementById("probv-" + lbl);
    if (fill) fill.style.width = w + "%";
    if (val)  val.textContent  = w + "%";
  }

  // Features
  featsCont.innerHTML = Object.entries(features_summary).map(([k, v]) => `
    <div class="feat">
      <div class="feat-key">${k}</div>
      <div class="feat-val">${typeof v === "number" ? v.toFixed(3) : v}</div>
    </div>`).join("");
}

// ── Recording ─────────────────────────────────────────────────────────────────
btnRecord.addEventListener("click", async () => {
  receivedWavChunks = [];
  transcriptEl.textContent = "—";
  LABELS.forEach(l => {
    const f = document.getElementById("prob-" + l);
    if (f) f.style.width = "0%";
  });

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm;codecs=opus" });
  audioChunks = [];

  openWS();

  mediaRecorder.ondataavailable = async ({ data }) => {
    if (data.size > 0 && ws && ws.readyState === WebSocket.OPEN) {
      // Convert Blob → ArrayBuffer → Float32Array PCM
      const ab  = await data.arrayBuffer();
      const ctx = new AudioContext({ sampleRate: 16000 });
      const decoded = await ctx.decodeAudioData(ab);
      const pcm = decoded.getChannelData(0); // mono float32
      const b64 = arrayToBase64(pcm);
      ws.send(JSON.stringify({ type: "audio_chunk", data: b64, sample_rate: 16000 }));
      ctx.close();
    }
  };

  mediaRecorder.onstop = () => {
    stream.getTracks().forEach(t => t.stop());
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({ type: "end_stream", sample_rate: 16000 }));
    }
    setStatus("Processing…", "active");
  };

  mediaRecorder.start(500); // emit chunks every 500ms
  btnRecord.disabled = true;
  btnStop.disabled   = false;
  setStatus("Recording…", "active");
});

btnStop.addEventListener("click", () => {
  mediaRecorder?.stop();
  btnRecord.disabled = false;
  btnStop.disabled   = true;
});

// ── File upload (via REST API) ─────────────────────────────────────────────
btnUpload.addEventListener("click", () => fileInput.click());

fileInput.addEventListener("change", async () => {
  const file = fileInput.files[0];
  if (!file) return;
  setStatus("Uploading & processing…", "active");
  receivedWavChunks = [];

  // 1. STT
  const fd1 = new FormData();
  fd1.append("file", file);
  fd1.append("language", "ko");
  const sttRes  = await fetch(`${API}/api/transcribe`, { method: "POST", body: fd1 });
  const sttData = await sttRes.json();
  transcriptEl.textContent = sttData.transcript;

  // 2. Emotion
  const fd2 = new FormData();
  fd2.append("file", file);
  fd2.append("transcript", sttData.transcript);
  const emoRes  = await fetch(`${API}/api/analyze-emotion`, { method: "POST", body: fd2 });
  const emoData = await emoRes.json();
  updateEmotion(emoData);

  // 3. TTS
  const ttsRes = await fetch(`${API}/api/synthesize`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      text:          sttData.transcript || "Hello.",
      emotion_label: emoData.emotion_label,
      intensity:     emoData.intensity,
    }),
  });
  const wavBlob = await ttsRes.blob();
  audioPlayer.src = URL.createObjectURL(wavBlob);
  audioPlayer.play();

  document.getElementById("m-stt").textContent     = sttData.latency_ms.toFixed(0) + " ms";
  document.getElementById("m-emotion").textContent = emoData.latency_ms.toFixed(0) + " ms";
  const hdr = ttsRes.headers.get("X-Latency-Ms");
  if (hdr) document.getElementById("m-tts").textContent = parseFloat(hdr).toFixed(0) + " ms";

  setStatus("Done", "active");
  fileInput.value = "";
});

// ── Utility ──────────────────────────────────────────────────────────────────
function arrayToBase64(float32) {
  const bytes = new Uint8Array(float32.buffer);
  let bin = "";
  for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);
  return btoa(bin);
}

function base64ToUint8(b64) {
  const bin = atob(b64);
  const arr = new Uint8Array(bin.length);
  for (let i = 0; i < bin.length; i++) arr[i] = bin.charCodeAt(i);
  return arr;
}
</script>
</body>
</html>
